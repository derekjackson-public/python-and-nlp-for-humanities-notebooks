{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecitng Spam in e-mail\n",
    "\n",
    "Observe that this is a classification problem, and uses supervised learning.\n",
    "\n",
    "Learning Objectives:\n",
    "1. A lot of NLP is preparing data\n",
    "2. You can use almost any Machine Learning algorithm as long as the data can be made to fit.\n",
    "\n",
    "## The Spam Database\n",
    "\n",
    "The data can be found here: [link to spam database at University of California Irvine](https://archive.ics.uci.edu/ml/datasets/Spambase)\n",
    "\n",
    "Note this data has been pre-processed. The details are noted below in the UCI documentation. Important to note that columns 1-48 are word frequency measures: the number of times words appear divided by number of words in the document * 100. Also the las colum is our target variable, the label, if an e-mail is or is not SPAM.\n",
    "\n",
    "There is a word frequency measure for each e-mail\n",
    "\n",
    "## UCI DOcumentation\n",
    "### Source:\n",
    "\n",
    "#### Creators:\n",
    "\n",
    "Mark Hopkins, Erik Reeber, George Forman, Jaap Suermondt\n",
    "Hewlett-Packard Labs, 1501 Page Mill Rd., Palo Alto, CA 94304\n",
    "\n",
    "#### Donor:\n",
    "\n",
    "George Forman (gforman at nospam hpl.hp.com) 650-857-7835\n",
    "\n",
    "### Data Set Information:\n",
    "\n",
    "The \"spam\" concept is diverse: advertisements for products/web sites, make money fast schemes, chain letters, pornography...\n",
    "\n",
    "Our collection of spam e-mails came from our postmaster and individuals who had filed spam. Our collection of non-spam e-mails came from filed work and personal e-mails, and hence the word 'george' and the area code '650' are indicators of non-spam. These are useful when constructing a personalized spam filter. One would either have to blind such non-spam indicators or get a very wide collection of non-spam to generate a general purpose spam filter.\n",
    "\n",
    "For background on spam:\n",
    "\n",
    "Cranor, Lorrie F., LaMacchia, Brian A. Spam!\n",
    "Communications of the ACM, 41(8):74-83, 1998.\n",
    "\n",
    "(a) Hewlett-Packard Internal-only Technical Report. External forthcoming.\n",
    "(b) Determine whether a given email is spam or not.\n",
    "(c) ~7% misclassification error. False positives (marking good mail as spam) are very undesirable.If we insist on zero false positives in the training/testing set, 20-25% of the spam passed through the filter.\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "The last column of 'spambase.data' denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail. The run-length attributes (55-57) measure the length of sequences of consecutive capital letters. For the statistical measures of each attribute, see the end of this file. Here are the definitions of the attributes:\n",
    "\n",
    "48 continuous real [0,100] attributes of type word_freq_WORD\n",
    "= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail. A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string.\n",
    "\n",
    "6 continuous real [0,100] attributes of type char_freq_CHAR]\n",
    "= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
    "\n",
    "1 continuous real [1,...] attribute of type capital_run_length_average\n",
    "= average length of uninterrupted sequences of capital letters\n",
    "\n",
    "1 continuous integer [1,...] attribute of type capital_run_length_longest\n",
    "= length of longest uninterrupted sequence of capital letters\n",
    "\n",
    "1 continuous integer [1,...] attribute of type capital_run_length_total\n",
    "= sum of length of uninterrupted sequences of capital letters\n",
    "= total number of capital letters in the e-mail\n",
    "\n",
    "1 nominal {0,1} class attribute of type spam\n",
    "= denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources\n",
    "* [sklearn naive_bayes MultinomialNB](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB)\n",
    "* [Naive Bayes](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)\n",
    "* [skleanr AdaBoost Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "* [AdaBoost](https://en.wikipedia.org/wiki/AdaBoost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the data as a matrix\n",
    "data = pd.read_csv('data/spambase.data').as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4600, 58)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only use the first 48 columns because this is the wod requency data we want to use (See documentation).\n",
    "\n",
    "We also know the last column holds the label (output) so we will use that column for our target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[:,:48]\n",
    "Y = data[:,-1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can split our datasets into training and testing groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X[:-100,]\n",
    "Y_train = Y[:-100,]\n",
    "x_test = X[-100:,]\n",
    "y_test = Y[-100:,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create the model. First instantiate the object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB()\n",
    "model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification rate for NB:  0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification rate for NB: \", model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We got a decent score of 90% accuracy but now we can easily try other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "\n",
    "Ada_model = AdaBoostClassifier()\n",
    "Ada_model.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification rate for ADA Boost Classifer:  0.92\n"
     ]
    }
   ],
   "source": [
    "print(\"Classification rate for ADA Boost Classifer: \", Ada_model.score(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we did even better with the ADA Boost Classifier.\n",
    "\n",
    "You can see here understanding and knowing the variety and distinctions between models is the key to successful Natural Language Processing and Machine Learning.\n",
    "\n",
    "In this example it is important to know we are doing a supervised learning, classification problem. So as long as I choose a model that is a classifier, and trains itself using a known label value (i.e. supervised learning) it is not necessarily important to know what the model is \"doing\" or how it works, but that it provides reliable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
